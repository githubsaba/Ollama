{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(base_url  =\"http://localhost:11434\",model =\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ROBERT\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n Certainly! Artificial Intelligence (AI) is a rapidly evolving field that has seen numerous groundbreaking discoveries and innovations. Here are some of the most significant research contributions in the field of AI:\\n\\n1. Alan Turing\\'s Turing Test (1950): Developed by British mathematician Alan Turing, this test is a measure of a machine\\'s ability to exhibit intelligent behavior comparable to that of a human. While not a direct research contribution, the Turing Test has served as a benchmark for evaluating the success of AI systems in mimicking human intelligence.\\n2. Arthur Samuel\\'s Work on Machine Learning (1950s): Samuel, an American computer scientist, is credited with developing the field of machine learning. His work laid the foundation for the development of algorithms that enable machines to learn from experience and improve their performance over time.\\n3. Marvin Minsky and Seymour Papert\\'s Perceptron (1960s): Minsky and Papert, both American cognitive scientists, developed the perceptron, a neural network architecture that can learn from data. Although it was later shown to have limitations, the perceptron paved the way for the development of more advanced neural networks.\\n4. John McCarthy\\'s Lisp Programming Language (1960s): McCarthy, an American computer scientist, created the Lisp programming language, which is still widely used today. Lisp has played a significant role in the development of AI, particularly in the areas of natural language processing and machine learning.\\n5. Yann LeCun\\'s Neural Networks (1980s): LeCun, a French-American computer scientist, is known for his work on neural networks, including the development of the backpropagation algorithm. This algorithm enables machines to learn from data more efficiently and has been instrumental in advancing the field of deep learning.\\n6. Andrew Ng\\'s Deep Learning (2000s): Ng, a Chinese-American computer scientist, has made significant contributions to the field of deep learning. He co-founded Coursera, an online learning platform, and has worked on various AI projects, including Google Brain and Baidu.\\n7. Geoffrey Hinton\\'s Recurrent Neural Networks (1980s): Hinton, a Canadian computer scientist, is known for his work on recurrent neural networks (RNNs), which are essential for modeling sequential data such as speech, text, or time series data.\\n8. Yoshua Bengio\\'s Recurrent Neural Networks (1980s): Bengio, a Canadian computer scientist, also worked on RNNs and made significant contributions to the field of deep learning. He is known for his work on the \"long short-term memory\" (LSTM) algorithm, which improves upon traditional RNN architectures.\\n9. JÃ¼rgen Schmidhuber\\'s Universal Approximation Theorem (1990s): Schmidhuber, a German computer scientist, proved the universal approximation theorem, which states that a neural network with sufficient capacity can approximate any continuous function on a compact domain to any desired degree of accuracy.\\n10. Ian Goodfellow\\'s Generative Adversarial Networks (2014): Goodfellow, an American computer scientist, introduced generative adversarial networks (GANs), which are a type of deep learning algorithm that can generate realistic synthetic data, such as images or videos. GANs have had a significant impact on the field of computer vision and beyond.\\n\\nThese are just a few examples of the many groundbreaking research contributions in the field of AI. As the field continues to evolve, we can expect new discoveries and innovations that will shape the future of AI.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"hi can you tell me the most significant research in the feild of AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
